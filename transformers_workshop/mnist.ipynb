{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lhall\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from transformers.modeling_outputs import ImageClassifierOutput\n",
    "from typing import List, Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "LR = 1e-3\n",
    "NUM_EPOCHS = 25\n",
    "IMG_SIZE = 28\n",
    "HIDDEN_DIM = 128\n",
    "INTERMEDIATE_DIM = 256\n",
    "NUM_BLOCKS = 1\n",
    "NUM_CLASSES = 10\n",
    "PATIENCE = 3\n",
    "LOGGING_STEPS = 100\n",
    "ATTENTION_HEAD_SIZE = 64\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train_dataset = datasets.MNIST('../data/MNIST/', download=True, train=True)\n",
    "test_dataset = datasets.MNIST('../data/MNIST/', download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (28, 28), Label: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Image shape: {np.array(train_dataset[0][0]).shape}, Label: {np.array(train_dataset[0][1])}')\n",
    "plt.imshow(np.array(train_dataset[0][0]).squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.13066047430038452, Std: 0.30810779333114624\n"
     ]
    }
   ],
   "source": [
    "# calcluate mean and std of the dataset\n",
    "mean = train_dataset.data.float().mean() / 255\n",
    "std = train_dataset.data.float().std() / 255\n",
    "print(f'Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize(mean, std)]\n",
    ")\n",
    "train_dataset = datasets.MNIST('../data/MNIST/', download=True, train=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../data/MNIST/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 28, 28]) torch.Size([512])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "for ex in test_loader:\n",
    "    print(ex[0].shape, ex[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollator:\n",
    "    def __call__(self, batch: List[Tuple[torch.Tensor, int]]) -> Dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            'x': torch.stack([f[0] for f in batch]),\n",
    "            'labels': torch.tensor([f[1] for f in batch])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.W_Q = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_K = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_V = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.sqrt_d = math.sqrt(hidden_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # (B, L, d)\n",
    "        Q = self.W_Q(x) # (B, L, d)\n",
    "        K = self.W_K(x) # (B, L, d)\n",
    "        V = self.W_V(x) # (B, L, d)\n",
    "        a = Q.matmul(K.permute(0, 2, 1)) / self.sqrt_d # (B, 50, 50)\n",
    "        a = a.softmax(dim=-1).matmul(V)\n",
    "        return a\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = ATTENTION_HEAD_SIZE\n",
    "        self.head_dim = hidden_dim // ATTENTION_HEAD_SIZE\n",
    "        self.W_Q = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_K = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_V = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.sqrt_d = math.sqrt(hidden_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # (batch_size, length, hidden_dim)\n",
    "        batch_size = x.size(0)  \n",
    "        Q = self.W_Q(x).reshape(batch_size, -1, self.num_heads, self.head_dim) # (batch_size, length, num_heads, head_dim)\n",
    "        K = self.W_K(x).reshape(batch_size, -1, self.num_heads, self.head_dim) # (batch_size, length, num_heads, head_dim)\n",
    "        V = self.W_V(x).reshape(batch_size, -1, self.num_heads, self.head_dim) # (batch_size, length, num_heads, head_dim)\n",
    "        Q = Q.transpose(1, 2) # (batch_size, num_heads, length, head_dim)\n",
    "        K = K.transpose(1, 2) # (batch_size, num_heads, length, head_dim)\n",
    "        V = V.transpose(1, 2) # (batch_size, num_heads, length, head_dim)\n",
    "        K = K.transpose(2, 3) # (batch_size, num_heads, head_dim, length)\n",
    "        a = Q.matmul(K) / self.sqrt_d # (batch_size, num_heads, length, length)\n",
    "        a = a.softmax(dim=-1) # (batch_size, num_heads, length, length)\n",
    "        a = a.matmul(V) # (batch_size, num_heads, length, head_dim)\n",
    "        a = a.transpose(1, 2) # (batch_size, length, num_heads, head_dim)\n",
    "        a = a.reshape(batch_size, -1, self.hidden_dim) # (batch_size, length, hidden_dim)\n",
    "        return a\n",
    "        \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, hidden_dim: torch.Tensor, intermediate_dim: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.w2 = nn.Linear(intermediate_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor: # (B, L, d)\n",
    "        return self.w2(F.relu(self.w1(x))) # (B, L, d)\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim: torch.Tensor, intermediate_dim: torch.Tensor, multi_head_attention: Optional[bool] = False):\n",
    "        super().__init__()\n",
    "        self.attention = Attention(hidden_dim) if not multi_head_attention else MultiHeadAttention(hidden_dim)\n",
    "        self.mlp = MLP(hidden_dim, intermediate_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "        attention_output = self.attention(x)\n",
    "        attention_output = attention_output + residual\n",
    "        residual = attention_output\n",
    "        mlp_output = self.mlp(attention_output)\n",
    "        mlp_output = mlp_output + residual\n",
    "        return mlp_output\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_dim: torch.Tensor, num_classes: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.out = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.out(F.relu(self.dense(x)))\n",
    "\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size: torch.Tensor, hidden_size: torch.Tensor, num_classes: torch.Tensor):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, labels: Optional[torch.Tensor] = None) -> ImageClassifierOutput:\n",
    "        # (batch_size, 1, 28, 28), (batch_size,)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        logits = self.fc2(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return ImageClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes: torch.Tensor):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(64 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, labels: Optional[torch.Tensor] = None) -> ImageClassifierOutput:\n",
    "        # (batch_size, 1, 28, 28), (batch_size,)\n",
    "        batch_size = x.size(0)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        logits = self.fc(x)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return ImageClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: torch.Tensor,\n",
    "        hidden_dim: torch.Tensor,\n",
    "        intermediate_dim: torch.Tensor,\n",
    "        num_classes: torch.Tensor,\n",
    "        num_blocks: torch.Tensor,\n",
    "        multi_head_attention: Optional[bool] = False\n",
    "    ):\n",
    "        super(ViT, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(hidden_dim, intermediate_dim, multi_head_attention) for _ in range(num_blocks)])\n",
    "        self.classifier = Classifier(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, labels: Optional[torch.Tensor] = None) -> ImageClassifierOutput:\n",
    "        # (batch_size, 1, 28, 28), (batch_size,)\n",
    "        batch_size = x.size(0)\n",
    "        img_size = x.size(-1)\n",
    "        x = x.view(batch_size, img_size, img_size) # (batch_size, 784)\n",
    "        x = self.embedding(x) # (batch_size, hidden_dim)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        h = x.mean(dim=1)\n",
    "        logits = self.classifier(h)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return ImageClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "SimpleNN                                 --\n",
      "├─Linear: 1-1                            100,480\n",
      "├─Linear: 1-2                            1,290\n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3067984580993652, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.1423, 'eval_runtime': 0.6427, 'eval_samples_per_second': 15558.748, 'eval_steps_per_second': 31.117}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2832' max='2950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2832/2950 01:37 < 00:04, 29.15 it/s, Epoch 24/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.495100</td>\n",
       "      <td>0.251798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.180421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178800</td>\n",
       "      <td>0.144043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.143600</td>\n",
       "      <td>0.121767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.110134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.967600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>0.093103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074400</td>\n",
       "      <td>0.088555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.973700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.081931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.081864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.079027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.074610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.073188</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.072167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.071087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.070137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.072580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>0.070216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.977900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.068555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.068295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.067891</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.067494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.067235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.06789097189903259, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.9796, 'eval_runtime': 0.5501, 'eval_samples_per_second': 18179.96, 'eval_steps_per_second': 36.36, 'epoch': 24.0}\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN                                      --\n",
      "├─Conv2d: 1-1                            320\n",
      "├─AvgPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            18,496\n",
      "├─AvgPool2d: 1-4                         --\n",
      "├─Linear: 1-5                            31,370\n",
      "=================================================================\n",
      "Total params: 50,186\n",
      "Trainable params: 50,186\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3123226165771484, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.0939, 'eval_runtime': 0.8079, 'eval_samples_per_second': 12377.909, 'eval_steps_per_second': 24.756}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1652' max='2950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1652/2950 01:07 < 00:52, 24.53 it/s, Epoch 14/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.549900</td>\n",
       "      <td>0.196953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.944600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.077817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089900</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068600</td>\n",
       "      <td>0.050271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.042430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047900</td>\n",
       "      <td>0.042136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.038967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.036387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.033353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.035909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.032714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.033923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.031599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.988400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.035805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03271351382136345, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.9885, 'eval_runtime': 0.5507, 'eval_samples_per_second': 18157.097, 'eval_steps_per_second': 36.314, 'epoch': 14.0}\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ViT                                      --\n",
      "├─Linear: 1-1                            3,712\n",
      "├─ModuleList: 1-2                        --\n",
      "│    └─TransformerBlock: 2-1             --\n",
      "│    │    └─Attention: 3-1               49,536\n",
      "│    │    └─MLP: 3-2                     65,920\n",
      "├─Classifier: 1-3                        --\n",
      "│    └─Linear: 2-2                       16,512\n",
      "│    └─Linear: 2-3                       1,290\n",
      "=================================================================\n",
      "Total params: 136,970\n",
      "Trainable params: 136,970\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.3201968669891357, 'eval_model_preparation_time': 0.0078, 'eval_accuracy': 0.0613, 'eval_runtime': 0.5438, 'eval_samples_per_second': 18389.545, 'eval_steps_per_second': 36.779}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2950' max='2950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2950/2950 01:56, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.481100</td>\n",
       "      <td>0.916120</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.690800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.898200</td>\n",
       "      <td>0.724722</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.742400</td>\n",
       "      <td>0.650322</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.654200</td>\n",
       "      <td>0.586446</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.804300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.597100</td>\n",
       "      <td>0.531106</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.505278</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.836100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>0.492095</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.467300</td>\n",
       "      <td>0.508036</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.833400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.443300</td>\n",
       "      <td>0.453430</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.855700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.435300</td>\n",
       "      <td>0.432445</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.862300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.428253</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.861500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.391900</td>\n",
       "      <td>0.413230</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.868900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.399751</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.367100</td>\n",
       "      <td>0.411900</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.865300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>0.413346</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.863400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.357700</td>\n",
       "      <td>0.387064</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.375635</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.367729</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.379268</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.882600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.334100</td>\n",
       "      <td>0.364404</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.885100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.319700</td>\n",
       "      <td>0.367859</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.361982</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.884700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.309900</td>\n",
       "      <td>0.356265</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.351883</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.305700</td>\n",
       "      <td>0.350209</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.890300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3502092957496643, 'eval_model_preparation_time': 0.0078, 'eval_accuracy': 0.8903, 'eval_runtime': 0.565, 'eval_samples_per_second': 17698.374, 'eval_steps_per_second': 35.397, 'epoch': 25.0}\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "ViT                                      --\n",
      "├─Linear: 1-1                            3,712\n",
      "├─ModuleList: 1-2                        --\n",
      "│    └─TransformerBlock: 2-1             --\n",
      "│    │    └─MultiHeadAttention: 3-1      49,536\n",
      "│    │    └─MLP: 3-2                     65,920\n",
      "├─Classifier: 1-3                        --\n",
      "│    └─Linear: 2-2                       16,512\n",
      "│    └─Linear: 2-3                       1,290\n",
      "=================================================================\n",
      "Total params: 136,970\n",
      "Trainable params: 136,970\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.307466745376587, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.1318, 'eval_runtime': 0.9466, 'eval_samples_per_second': 10564.55, 'eval_steps_per_second': 21.129}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2950' max='2950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2950/2950 02:57, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.521700</td>\n",
       "      <td>0.794701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.754900</td>\n",
       "      <td>0.558931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.817800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.457426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.852700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.455300</td>\n",
       "      <td>0.391060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.872800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.361419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.886100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.336300</td>\n",
       "      <td>0.363883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.312700</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.294200</td>\n",
       "      <td>0.306466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.901500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.305226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.902000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.299222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.254300</td>\n",
       "      <td>0.321903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.893600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.288096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.226200</td>\n",
       "      <td>0.277698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.217200</td>\n",
       "      <td>0.275512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.212200</td>\n",
       "      <td>0.264210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.206200</td>\n",
       "      <td>0.265170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.915700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>0.261876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.914900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.260636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.182700</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.256223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.259169</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.919000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.252432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.164100</td>\n",
       "      <td>0.250174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.158900</td>\n",
       "      <td>0.245997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.922200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.160600</td>\n",
       "      <td>0.243740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24373950064182281, 'eval_model_preparation_time': 0.0, 'eval_accuracy': 0.9241, 'eval_runtime': 0.6686, 'eval_samples_per_second': 14957.408, 'eval_steps_per_second': 29.915, 'epoch': 25.0}\n",
      "{'Convolutional Neural Network': 0.9885, 'Simple Neural Network': 0.9796, 'Vision Transformer with Multi-Head Attention': 0.9241, 'Vision Transformer': 0.8903}\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LR,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=LOGGING_STEPS,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    accuracy = (predictions == labels).mean()\n",
    "    return {'accuracy': accuracy}\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Simple Neural Network': SimpleNN(input_size=IMG_SIZE*IMG_SIZE, hidden_size=HIDDEN_DIM, num_classes=NUM_CLASSES),\n",
    "    'Convolutional Neural Network': CNN(num_classes=NUM_CLASSES),\n",
    "    'Vision Transformer': ViT(input_dim=IMG_SIZE, hidden_dim=HIDDEN_DIM, intermediate_dim=INTERMEDIATE_DIM, num_classes=NUM_CLASSES, num_blocks=NUM_BLOCKS),\n",
    "    'Vision Transformer with Multi-Head Attention': ViT(input_dim=IMG_SIZE, hidden_dim=HIDDEN_DIM, intermediate_dim=INTERMEDIATE_DIM, num_classes=NUM_CLASSES, num_blocks=NUM_BLOCKS, multi_head_attention=True),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for model_name, model in models.items():\n",
    "    print(summary(model))\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollator(),\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)]\n",
    "    )\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    print(metrics)\n",
    "    trainer.accelerator.free_memory()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    final_accuracy = metrics['eval_accuracy']\n",
    "    results[model_name] = final_accuracy\n",
    "\n",
    "\n",
    "# sort results by accuracy\n",
    "results = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViT(\n",
      "  (embedding): Linear(in_features=28, out_features=128, bias=True)\n",
      "  (blocks): ModuleList(\n",
      "    (0): TransformerBlock(\n",
      "      (attention): MultiHeadAttention(\n",
      "        (W_Q): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (W_K): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (W_V): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "      (mlp): MLP(\n",
      "        (w1): Linear(in_features=128, out_features=256, bias=True)\n",
      "        (w2): Linear(in_features=256, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (dense): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (out): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer_model = trainer.model\n",
    "print(transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "HFViT                                    --\n",
       "├─Linear: 1-1                            3,712\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─TransformerBlock: 2-1             --\n",
       "│    │    └─MultiHeadAttention: 3-1      49,536\n",
       "│    │    └─MLP: 3-2                     65,920\n",
       "├─Classifier: 1-3                        --\n",
       "│    └─Linear: 2-2                       16,512\n",
       "│    └─Linear: 2-3                       1,290\n",
       "=================================================================\n",
       "Total params: 136,970\n",
       "Trainable params: 136,970\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PretrainedConfig, PreTrainedModel\n",
    "\n",
    "\n",
    "class HFViTConfig(PretrainedConfig):\n",
    "    model_type = \"vit\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_size: int,\n",
    "        intermediate_size: int,\n",
    "        num_hidden_layers: int,\n",
    "        num_classes: int,\n",
    "        multi_head_attention: bool,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.multi_head_attention = multi_head_attention\n",
    "\n",
    "\n",
    "\n",
    "class HFViT(PreTrainedModel):\n",
    "    config_class = HFViTConfig\n",
    "    def __init__(self, config: HFViTConfig):\n",
    "        super().__init__(config)\n",
    "        self.embedding = nn.Linear(config.input_dim, config.hidden_size)\n",
    "        self.blocks = nn.ModuleList([TransformerBlock(config.hidden_size, config.intermediate_size, config.multi_head_attention) for _ in range(config.num_hidden_layers)])\n",
    "        self.classifier = Classifier(config.hidden_size, config.num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, labels: Optional[torch.Tensor] = None) -> ImageClassifierOutput:\n",
    "        # (batch_size, 1, 28, 28), (batch_size,)\n",
    "        batch_size = x.size(0)\n",
    "        img_size = x.size(-1)\n",
    "        x = x.view(batch_size, img_size, img_size) # (batch_size, 784)\n",
    "        x = self.embedding(x) # (batch_size, hidden_dim)\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        h = x.mean(dim=1)\n",
    "        logits = self.classifier(h)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return ImageClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits\n",
    "        )\n",
    "\n",
    "\n",
    "config = HFViTConfig(input_dim=IMG_SIZE, hidden_size=HIDDEN_DIM, intermediate_size=INTERMEDIATE_DIM, num_hidden_layers=NUM_BLOCKS, num_classes=NUM_CLASSES, multi_head_attention=True)\n",
    "hf_model = HFViT(config)\n",
    "summary(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "HFViT                                    --\n",
       "├─Linear: 1-1                            3,712\n",
       "├─ModuleList: 1-2                        --\n",
       "│    └─TransformerBlock: 2-1             --\n",
       "│    │    └─MultiHeadAttention: 3-1      49,536\n",
       "│    │    └─MLP: 3-2                     65,920\n",
       "├─Classifier: 1-3                        --\n",
       "│    └─Linear: 2-2                       16,512\n",
       "│    └─Linear: 2-3                       1,290\n",
       "=================================================================\n",
       "Total params: 136,970\n",
       "Trainable params: 136,970\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_model.load_state_dict(transformer_model.state_dict())\n",
    "summary(hf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model.push_to_hub('lhallee/mnist-vit', private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model.load_from_hub('lhallee/mnist-vit')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
